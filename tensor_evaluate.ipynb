{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_structures import Instance\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 5000\n",
    "instance = Instance.generate(size,20,seed=200) #This has to be faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precalc\n",
    "\n",
    "synSet = instance.synSet\n",
    "gains = torch.tensor(list(instance.polynomial_gains.values()))\n",
    "costs = instance.costs.T\n",
    "budget = instance.budget\n",
    "gamma = instance.gamma\n",
    "profits = torch.tensor(instance.profits)\n",
    "lower_costs = torch.tensor(costs[0])\n",
    "upper_costs = torch.tensor(costs[1])\n",
    "delta_costs = upper_costs-lower_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0,  ..., 0, 0, 0]) 70683.95470246754\n"
     ]
    }
   ],
   "source": [
    "#Yes, this is bad, but im lazy\n",
    "sol = torch.zeros(size,dtype=torch.int64)\n",
    "for i in range(size):\n",
    "    if torch.rand(1).item() > 0.7:\n",
    "        sol[i] = 1\n",
    "\n",
    "a = instance.evaluate(sol)\n",
    "print(sol,a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500):\n",
    "    a = instance.evaluate(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a():\n",
    "    item_vec = torch.arange(1,size+1)\n",
    "    indices_ordenados = torch.argsort(delta_costs,descending=True) #Ordenar los indices primero en base a los delta_costs, me ahorra sorts\n",
    "    item_vec = item_vec[indices_ordenados]\n",
    "    ordered_sol = sol[indices_ordenados]\n",
    "    investments = torch.multiply(ordered_sol,item_vec)\n",
    "    investments = investments[investments > 0] - 1\n",
    "    total_upper_costs = torch.sum(upper_costs[investments[:gamma]])\n",
    "    total_lower_costs = torch.sum(lower_costs[investments[gamma:]])\n",
    "    total_costs = total_upper_costs + total_lower_costs\n",
    "    if total_costs <= budget:\n",
    "        of = torch.sum(profits[investments]) - total_costs\n",
    "        investment_set = set(investments)\n",
    "        for i,syn in enumerate(synSet):\n",
    "            #es_subconjunto = torch.isin(torch.tensor(list(syn)), investments).all().item()\n",
    "            if syn.issubset(investment_set):\n",
    "                of += gains[i]\n",
    "\n",
    "    return of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500):\n",
    "    b = a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True,  True],\n",
      "        [False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Definir los tensores\n",
    "tensor_grande = torch.tensor([1, 2, 3, 4])\n",
    "tensor_pequeno = torch.tensor([[3,2],[5,6]])\n",
    "\n",
    "# Verificar si tensor_pequeno es un subconjunto de tensor_grande\n",
    "es_subconjunto = torch.isin(tensor_pequeno, tensor_grande)\n",
    "print(es_subconjunto)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
