{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_structures import Instance\n",
    "from src.solvers.OG.model import CustomSolver,Net\n",
    "from src.solvers.OG.integer_quantizer import KmeansQuantizer\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from functools import partial\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = Instance.generate(100,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = CustomSolver(instance=instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124.96779143381195\n",
      "tensor([47.8174, -3.8432, 43.8746, -4.9404, 29.5989, -3.9260, -3.0228, -3.8614,\n",
      "        -7.3067,  6.9368, -4.7404, -5.7356, -5.4328, 22.3152, 38.9871,  5.7048,\n",
      "        -3.9408,  1.2738, 21.1678, -4.2835])\n"
     ]
    }
   ],
   "source": [
    "from src.solvers.OG.integer_quantizer import EmbeddingQuantizer\n",
    "\n",
    "benefit_data = solver.benefit_data\n",
    "#quantizer = KmeansQuantizer(benefit_data,100)\n",
    "quantizer = EmbeddingQuantizer(benefit_data,1,20,1000,1)\n",
    "solver.set_integer_quantizer(quantizer)\n",
    "print(solver.quantizer.cluster_centers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 1., 0., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = solver.create_vectorized_data()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = solver.quantizer.indexes().view(-1,1)\n",
    "#Normalizo y \n",
    "y_size = torch.max(y)+1\n",
    "\n",
    "def tupla_a_vector_binario(tupla,size):\n",
    "    output = np.zeros(size)\n",
    "    for i in tupla:\n",
    "        output[i] = 1\n",
    "    return output\n",
    "\n",
    "y = torch.tensor(np.array(list(map(partial(tupla_a_vector_binario,size=y_size),y)),dtype=np.float32))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a la definicion anterior estoy intendando predecir el indice y, en base a la tupla polinomial vectorizada x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intentar adivinar el indice\n",
    "\n",
    "net = Net(solver.instance.n_items,y_size)\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = optim.SGD(net.parameters(),lr = 1)\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(x,y)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,batch_size=3,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 0.015238588406104456"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99, Loss 0.0030656603433440893"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        batch_output = net(batch_x)\n",
    "        batch_loss = criterion(batch_output, batch_y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += batch_loss.item()\n",
    "    \n",
    "    sys.stdout.write(f'\\rEpoch {epoch}, Loss {total_loss / len(dataloader)}')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora uso la red para calcular el beneficio aproximado de cada item\n",
    "canon = torch.eye(instance.n_items)\n",
    "vectorized_predicted_indexes = net(canon)\n",
    "predicted_indexes = torch.argmax(vectorized_predicted_indexes,dim=1)\n",
    "\n",
    "predicted_value_per_item = torch.index_select(solver.quantizer.cluster_centers(), 0, predicted_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83709/1670099730.py:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /build/python-pytorch/src/pytorch-opt/aten/src/ATen/native/TensorShape.cpp:3571.)\n",
      "  predicted_value_per_item.T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([3.9314, 8.9468, 3.9314, 3.9314, 3.9314, 3.9314, 8.9468, 8.9468, 3.9314,\n",
       "        3.9314, 3.9314, 8.9468, 8.9468, 3.9314, 8.9468, 3.9314, 3.9314, 3.9314,\n",
       "        3.9314, 3.9314, 3.9314, 3.9314, 3.9314, 3.9314, 8.9468, 3.9314, 8.9468,\n",
       "        3.9314, 3.9314, 3.9314, 3.9314, 8.9468, 3.9314, 3.9314, 8.9468, 3.9314,\n",
       "        3.9314, 3.9314, 3.9314, 3.9314, 8.9468, 3.9314, 3.9314, 8.9468, 3.9314,\n",
       "        8.9468, 8.9468, 8.9468, 8.9468, 8.9468, 8.9468, 3.9314, 3.9314, 8.9468,\n",
       "        3.9314, 8.9468, 3.9314, 3.9314, 3.9314, 3.9314, 3.9314, 3.9314, 3.9314,\n",
       "        3.9314, 8.9468, 8.9468, 3.9314, 8.9468, 3.9314, 8.9468, 3.9314, 3.9314,\n",
       "        3.9314, 3.9314, 3.9314, 8.9468, 3.9314, 3.9314, 3.9314, 3.9314, 3.9314,\n",
       "        3.9314, 3.9314, 3.9314, 8.9468, 3.9314, 3.9314, 8.9468, 3.9314, 3.9314,\n",
       "        8.9468, 3.9314, 3.9314, 3.9314, 3.9314, 8.9468, 8.9468, 8.9468, 3.9314,\n",
       "        8.9468])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_value_per_item.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.solvers.collection import SolverCollection,Solution\n",
    "profits = torch.tensor(instance.profits).view(-1,1)\n",
    "profits = (profits+predicted_value_per_item).T.detach().numpy()[0]\n",
    "instance2 = Instance(instance.n_items,instance.gamma,instance.budget,profits,instance.costs,dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sol(of:2790.250103133364,time:0.04005885124206543)\n"
     ]
    }
   ],
   "source": [
    "base_instance = Instance(instance.n_items,instance.gamma,instance.budget,instance.profits,instance.costs,dict())\n",
    "base_sol = SolverCollection.gurobi_optimal(base_instance)\n",
    "print(base_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sol(of:3391.2562244007863,time:0.04061722755432129)\n"
     ]
    }
   ],
   "source": [
    "#Sol with predicted values\n",
    "\n",
    "\n",
    "sol2 = SolverCollection.gurobi_optimal(instance2)\n",
    "o = instance.evaluate(sol2.sol)\n",
    "final_sol = Solution(o,sol2.sol,sol2.time)\n",
    "print(final_sol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sol(of:3653.646907688214,time:0.5654070377349854)\n"
     ]
    }
   ],
   "source": [
    "optimal_sol = SolverCollection.gurobi_optimal(instance)\n",
    "print(optimal_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.3.0 when using version 1.3.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.3.0 when using version 1.3.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.3.0 when using version 1.3.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.3.0 when using version 1.3.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sol(of:3653.646907688214,time:0.7768564224243164)\n"
     ]
    }
   ],
   "source": [
    "baldo_sol = SolverCollection.baldo_ML(instance)\n",
    "print(baldo_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sol(of:3576.09511422617,time:0.4122023582458496)\n"
     ]
    }
   ],
   "source": [
    "ga_sol = SolverCollection.baldo_GA(instance)\n",
    "print(ga_sol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
