{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *\n",
    "from src.data_structures import Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = Instance.generate(1000,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75450/3924710133.py:24: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  training_data = pd.append(pd)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7424.000000</td>\n",
       "      <td>7424.000000</td>\n",
       "      <td>7424.000000</td>\n",
       "      <td>7424.000000</td>\n",
       "      <td>7424.000000</td>\n",
       "      <td>7424.000000</td>\n",
       "      <td>7424.000000</td>\n",
       "      <td>7424.000000</td>\n",
       "      <td>7424.000000</td>\n",
       "      <td>7424.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7424.000000</td>\n",
       "      <td>7424.000000</td>\n",
       "      <td>7424.000000</td>\n",
       "      <td>7424.000000</td>\n",
       "      <td>7424.000000</td>\n",
       "      <td>7424.000000</td>\n",
       "      <td>7424.000000</td>\n",
       "      <td>7424.000000</td>\n",
       "      <td>7424.00000</td>\n",
       "      <td>7424.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1855.500000</td>\n",
       "      <td>0.011853</td>\n",
       "      <td>0.016164</td>\n",
       "      <td>0.016164</td>\n",
       "      <td>0.013470</td>\n",
       "      <td>0.012123</td>\n",
       "      <td>0.012931</td>\n",
       "      <td>0.011045</td>\n",
       "      <td>0.015086</td>\n",
       "      <td>0.014278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011045</td>\n",
       "      <td>0.014009</td>\n",
       "      <td>0.011584</td>\n",
       "      <td>0.013739</td>\n",
       "      <td>0.014547</td>\n",
       "      <td>0.010776</td>\n",
       "      <td>0.009698</td>\n",
       "      <td>0.012662</td>\n",
       "      <td>0.01320</td>\n",
       "      <td>9.826028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1071.634237</td>\n",
       "      <td>0.108234</td>\n",
       "      <td>0.126114</td>\n",
       "      <td>0.126114</td>\n",
       "      <td>0.115283</td>\n",
       "      <td>0.109442</td>\n",
       "      <td>0.112985</td>\n",
       "      <td>0.104521</td>\n",
       "      <td>0.121904</td>\n",
       "      <td>0.118643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104521</td>\n",
       "      <td>0.117534</td>\n",
       "      <td>0.107011</td>\n",
       "      <td>0.116414</td>\n",
       "      <td>0.119740</td>\n",
       "      <td>0.103253</td>\n",
       "      <td>0.098008</td>\n",
       "      <td>0.111817</td>\n",
       "      <td>0.11414</td>\n",
       "      <td>10.350407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>927.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.640590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1855.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.711743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2783.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>13.070550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3711.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>49.870481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             index            0            1            2            3  \\\n",
       "count  7424.000000  7424.000000  7424.000000  7424.000000  7424.000000   \n",
       "mean   1855.500000     0.011853     0.016164     0.016164     0.013470   \n",
       "std    1071.634237     0.108234     0.126114     0.126114     0.115283   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%     927.750000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%    1855.500000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%    2783.250000     0.000000     0.000000     0.000000     0.000000   \n",
       "max    3711.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                 4            5            6            7            8  ...  \\\n",
       "count  7424.000000  7424.000000  7424.000000  7424.000000  7424.000000  ...   \n",
       "mean      0.012123     0.012931     0.011045     0.015086     0.014278  ...   \n",
       "std       0.109442     0.112985     0.104521     0.121904     0.118643  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "\n",
       "               991          992          993          994          995  \\\n",
       "count  7424.000000  7424.000000  7424.000000  7424.000000  7424.000000   \n",
       "mean      0.011045     0.014009     0.011584     0.013739     0.014547   \n",
       "std       0.104521     0.117534     0.107011     0.116414     0.119740   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               996          997          998         999        value  \n",
       "count  7424.000000  7424.000000  7424.000000  7424.00000  7424.000000  \n",
       "mean      0.010776     0.009698     0.012662     0.01320     9.826028  \n",
       "std       0.103253     0.098008     0.111817     0.11414    10.350407  \n",
       "min       0.000000     0.000000     0.000000     0.00000     1.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.00000     2.640590  \n",
       "50%       0.000000     0.000000     0.000000     0.00000     5.711743  \n",
       "75%       0.000000     0.000000     0.000000     0.00000    13.070550  \n",
       "max       1.000000     1.000000     1.000000     1.00000    49.870481  \n",
       "\n",
       "[8 rows x 1002 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "powers_of_two = np.array([2**i for i in range(0,32)])\n",
    "len(powers_of_two)\n",
    "\n",
    "def tuple_to_vec(tupla):\n",
    "    output = np.zeros(instance.n_items)\n",
    "    for element in tupla:\n",
    "        output[element-1] = 1\n",
    "    return output\n",
    "\n",
    "a = []\n",
    "evals = []\n",
    "for key,value in instance.polynomial_gains.items():\n",
    "    b = tuple_to_vec(Instance.key_to_tuple(key))\n",
    "    a.append(b)\n",
    "    evals.append(value)\n",
    "\n",
    "from pandas import DataFrame\n",
    "evals = np.array(evals).reshape(-1,1)\n",
    "a = np.vstack(a)\n",
    "concatenated = np.concatenate((a,evals), axis=1)\n",
    "data_features = [str(i) for i in range(instance.n_items)]\n",
    "data_features.append(\"value\")\n",
    "pd = DataFrame(concatenated,columns=data_features)\n",
    "training_data = pd.append(pd)\n",
    "training_data = training_data.reset_index()\n",
    "\n",
    "training_data.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows = len(instance.polynomial_gains.keys())*2\n",
    "mask = [False for i in range(rows)]\n",
    "for i in range(rows//2,rows):\n",
    "    mask[i] = True\n",
    "splitter = MaskSplitter(mask)(training_data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3712\n",
      "7424\n",
      "      index    0    1    2    3    4    5    6    7    8  ...  991  992  993  \\\n",
      "0         0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "1         1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2         2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "3         3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "4         4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "7419   3707  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0   \n",
      "7420   3708  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "7421   3709  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "7422   3710  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "7423   3711  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "\n",
      "      994  995  996  997  998  999      value  \n",
      "0     0.0  0.0  0.0  0.0  0.0  0.0  12.438617  \n",
      "1     0.0  0.0  0.0  0.0  0.0  0.0  45.591778  \n",
      "2     0.0  0.0  0.0  0.0  0.0  0.0   6.787297  \n",
      "3     0.0  0.0  0.0  0.0  0.0  0.0  34.971709  \n",
      "4     0.0  0.0  0.0  0.0  0.0  0.0  40.125155  \n",
      "...   ...  ...  ...  ...  ...  ...        ...  \n",
      "7419  0.0  0.0  0.0  0.0  0.0  0.0   1.011937  \n",
      "7420  0.0  1.0  0.0  0.0  0.0  0.0   1.010656  \n",
      "7421  1.0  0.0  0.0  0.0  0.0  0.0   1.003742  \n",
      "7422  1.0  0.0  0.0  0.0  0.0  0.0   1.004472  \n",
      "7423  0.0  0.0  0.0  0.0  0.0  0.0   1.000000  \n",
      "\n",
      "[7424 rows x 1002 columns]\n"
     ]
    }
   ],
   "source": [
    "print(len(instance.polynomial_gains.keys()))\n",
    "print(len(mask))\n",
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = TabularPandas(\n",
    "                training_data,\n",
    "                splits = splitter,\n",
    "                procs = [],\n",
    "                cat_names = \n",
    "                        [],\n",
    "                cont_names = \n",
    "                                [str(i) for i in range(instance.n_items)],\n",
    "                y_names = [\"value\"] ,\n",
    "                y_block = RegressionBlock()).dataloaders(path=\".\",bs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='371' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/371 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner = tabular_learner(dls,metrics=accuracy,layers = [10]*20)\n",
    "\n",
    "learner.fit(1,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.031623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3            4  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.001000     0.001000     0.001000     0.001000     0.001000   \n",
       "std       0.031623     0.031623     0.031623     0.031623     0.031623   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                 5            6            7            8            9  ...  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  ...   \n",
       "mean      0.001000     0.001000     0.001000     0.001000     0.001000  ...   \n",
       "std       0.031623     0.031623     0.031623     0.031623     0.031623  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "\n",
       "               990          991          992          993          994  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.001000     0.001000     0.001000     0.001000     0.001000   \n",
       "std       0.031623     0.031623     0.031623     0.031623     0.031623   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               995          996          997          998          999  \n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
       "mean      0.001000     0.001000     0.001000     0.001000     0.001000  \n",
       "std       0.031623     0.031623     0.031623     0.031623     0.031623  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 1000 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "for i in range(instance.n_items):\n",
    "    row = np.zeros(instance.n_items)\n",
    "    row[i] = 1\n",
    "    a.append(row)\n",
    "a = np.vstack(a)\n",
    "data_features = [str(i) for i in range(instance.n_items)]\n",
    "pd = DataFrame(a,columns=data_features)\n",
    "pd.describe()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dl = learner.dls.test_dl(pd)\n",
    "preds, _ = learner.get_preds(dl=test_dl,reorder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11.3306,  7.2735, 11.2187,  9.5580, 12.5589,  7.2747,  7.1931, 11.2188,\n",
       "         11.2182, 11.2547, 12.5589, 12.1953, 11.2184, 10.7464,  9.5159, 10.8309,\n",
       "          7.1986, 12.3764, 12.4621, 11.2692, 10.7653, 12.5589, 12.5589, 11.3226,\n",
       "         11.2178, 12.5589, 12.5589, 12.5589, 12.5687,  7.1877,  7.2101, 12.5589,\n",
       "         11.2182, 10.9669, 12.5589, 11.2850,  7.2760, 12.5138, 12.5589,  7.1737,\n",
       "          7.2693, 11.3880, 12.3357, 11.2801, 11.0391,  7.1930, 12.3149,  7.2780,\n",
       "         11.3760, 12.5589,  7.2705, 12.5589, 10.8407, 12.5589, 12.4040, 12.5589,\n",
       "         10.5172, 12.5916,  7.2185,  7.1940, 12.5589, 11.2899, 11.3302, 12.5589,\n",
       "         12.5589, 11.3321, 12.5589, 11.3314, 12.5589, 11.0958,  7.1881, 11.3314,\n",
       "         10.1799, 12.5589, 10.6631, 12.1800, 12.5073, 11.3607,  7.2120, 12.5589,\n",
       "          7.1925, 11.3766, 12.1952, 12.5961, 11.3687,  7.1870, 11.3704,  9.5861,\n",
       "          9.7144,  9.5116, 12.0823, 11.9388, 12.5641, 11.3977, 11.2212, 12.4819,\n",
       "         10.1110, 12.1821, 11.3481,  7.1812, 11.2240, 12.5589, 12.5589,  7.1928,\n",
       "         11.3658, 11.3748, 11.2899, 10.9620,  7.1908, 12.5589,  7.2109, 12.5952,\n",
       "         10.7556, 11.2286, 12.5589, 11.3482, 12.4386, 11.3304, 12.5037, 11.3742,\n",
       "         11.2404, 11.3717, 12.5589, 10.9118, 12.5589, 11.4789,  9.7302, 10.9486,\n",
       "         10.7504, 12.5589, 10.7598, 12.5589, 12.5589, 11.2200, 10.4872, 10.8571,\n",
       "          7.1872, 12.3632, 11.2181, 11.3634,  9.5287, 11.3522, 12.5589, 12.5589,\n",
       "         12.5589, 12.5589, 12.5589, 12.5589,  9.7342, 12.5589, 11.3311, 11.3698,\n",
       "          7.1872, 12.3555, 11.4689, 12.5589, 12.3107,  7.1893, 11.3301, 11.1061,\n",
       "         12.5589, 12.5519, 12.5589, 12.5589, 12.5589, 11.3542, 11.3723, 11.0287,\n",
       "         10.1207, 12.5589, 11.2303,  7.1906,  7.1905, 12.3696,  9.4714, 12.5589,\n",
       "         12.1257, 12.5589,  7.1882, 11.2769,  7.1897, 11.3701,  7.1920, 12.5867,\n",
       "         11.0462, 10.1571, 11.3310, 12.5589, 12.5589, 10.7249, 11.2269, 12.5589,\n",
       "         12.5589, 11.2193, 11.2210, 10.6768, 11.2733, 12.4048, 11.3624, 12.5622,\n",
       "         10.9695,  9.5581, 12.5589, 11.2460, 12.5589, 12.5917, 12.5917, 12.5589,\n",
       "          7.1891, 10.1710, 10.7507, 11.2330, 11.3757, 12.5589, 12.5589, 12.5062,\n",
       "         12.5589, 12.5589,  7.1897, 11.2683, 12.5589, 12.5962, 12.3044,  9.5532,\n",
       "         10.8127, 11.3799, 11.3566, 10.8215, 10.0807, 12.5681, 11.2882, 12.5769,\n",
       "         12.5589, 12.3514, 11.3304, 11.9232, 11.3305, 12.1430, 12.5589, 10.2022,\n",
       "         12.1771, 12.4794, 12.2854, 12.5589,  9.9873, 12.5589, 12.5589, 11.2337,\n",
       "         11.3357,  9.7228,  8.7786, 11.2883,  9.5404, 11.2527, 11.3651, 12.5589,\n",
       "         12.5589, 12.4009,  7.1927, 12.5939, 12.5957, 11.3725,  7.1849, 10.7643,\n",
       "         11.2208,  7.1826, 12.5589, 11.3165,  7.1880, 11.3354, 12.1225, 11.3302,\n",
       "          9.5615, 12.4782, 12.5589, 12.5890, 11.8832, 10.8678, 11.3604, 12.5589,\n",
       "         12.5589,  7.1940, 12.5589, 11.2380, 12.5589, 12.5589,  9.5543, 11.2682,\n",
       "         12.5589, 11.3384, 12.5589,  7.2255, 12.5589, 10.4444,  7.1935, 12.5589,\n",
       "         10.9745, 12.5589, 12.5589, 12.5589, 11.2765, 12.5589, 12.5561, 12.5802,\n",
       "         11.2664, 12.5589, 11.2687, 11.0763,  7.1878, 12.5589, 12.5589,  9.5593,\n",
       "         10.7524,  9.6948, 11.2316,  7.1900, 12.5589, 12.5701, 12.5589, 11.3004,\n",
       "         12.5589, 12.5589, 11.3138, 12.5589, 12.5589, 10.7639, 11.3662, 12.5589,\n",
       "         12.5884, 12.5589,  7.1905, 11.3581, 12.5589,  9.6939, 11.3564, 11.3727,\n",
       "         12.5589, 12.5589,  7.1814, 11.4033, 12.5589, 12.4873, 11.3194, 12.4063,\n",
       "         11.3336, 12.5589, 10.2034, 12.5589, 12.5589, 11.2136, 12.5589,  7.1788,\n",
       "         12.0119, 12.5303, 11.2781, 11.4278, 10.7517, 11.2179, 11.3351, 11.2446,\n",
       "         12.3032, 11.3319, 12.5589, 12.5589, 12.5589, 10.5896,  4.8437,  7.1867,\n",
       "         12.1156, 11.3759, 12.5589, 12.5961, 11.3537, 12.5684, 12.5559, 12.5589,\n",
       "         12.5589, 11.3083, 11.3356,  9.5018, 12.5589, 12.5589, 11.8935, 11.3703,\n",
       "         12.5589, 10.7672, 12.5589, 12.1694, 12.5932, 12.5589, 11.3308, 12.3062,\n",
       "         10.7672, 12.5589,  7.2452,  9.5567,  9.8210, 12.4306, 11.3962, 11.1798,\n",
       "         11.0326, 12.5589, 12.5621,  9.5580,  9.6800, 12.5589, 12.2379, 10.3449,\n",
       "         12.5922, 10.7483, 11.2494,  7.3345, 12.5589, 11.3772,  9.5592, 11.3377,\n",
       "         12.3663, 11.2646,  9.5574, 12.5589, 10.9062, 10.7520,  7.1783, 11.3555,\n",
       "         12.5892,  8.3666,  7.2699, 11.3201,  7.2152, 11.3736, 10.7712, 11.2800,\n",
       "         11.3409, 12.5976, 12.5588, 11.3300, 10.9545, 12.5663, 11.2889, 11.3317,\n",
       "         12.5589,  7.1791, 12.3919, 11.3629, 12.5707, 12.5589, 12.5213, 12.5972,\n",
       "          9.5593, 12.5589, 12.5589, 12.5514, 11.1492, 11.9069, 12.5589, 12.5589,\n",
       "         12.5589, 12.5589, 13.4613, 12.2649, 12.5589, 11.3338,  9.6635, 12.5313,\n",
       "         10.7514, 12.5589, 12.5589, 12.5589, 12.5589, 11.3699, 12.5917, 12.4033,\n",
       "         11.2192, 11.3316,  7.1865, 12.4553, 12.5236, 10.6046, 12.5926, 12.5589,\n",
       "         12.5975, 12.3772, 12.5439, 12.5589, 12.5589, 12.5589, 12.4757, 11.4257,\n",
       "         10.7452, 12.1653, 12.5589, 12.5589, 12.3749, 11.1679, 12.5589,  9.5304,\n",
       "         10.7070, 10.7631, 11.3723,  9.4711, 12.5589,  7.2399,  7.1735, 11.3225,\n",
       "          7.1840, 11.3684, 11.2374, 12.5589, 11.3058,  7.1922, 12.0922, 12.2789,\n",
       "          9.5577, 12.5944, 12.5589, 11.3730, 11.3053, 12.5670, 12.5589, 12.5985,\n",
       "         11.3031,  9.4946, 12.5632,  7.1893, 11.3929, 11.3793, 12.5589, 12.5589,\n",
       "         12.5589,  7.1881, 12.3953, 11.2848, 12.5589, 10.7524, 12.5589, 12.5589,\n",
       "         12.5589, 12.5589, 12.5589, 12.5589, 12.5952, 12.5589,  7.1824, 12.5589,\n",
       "         11.3681, 12.5589, 12.5589, 11.3124, 12.5589, 11.2877, 12.5589, 12.5589,\n",
       "         12.5888, 11.3395, 12.5589,  7.4053, 11.3598,  9.5615, 12.2503, 11.2363,\n",
       "         12.5589, 12.5589, 12.5589, 11.2212, 12.5589, 12.5429, 10.9093, 12.5589,\n",
       "         12.1906, 11.0708, 12.5589, 12.5589,  9.5615, 12.5589, 12.2234, 12.5589,\n",
       "         11.1091, 12.5589, 12.3466,  8.6206, 12.5589, 12.5589, 12.3222, 12.5589,\n",
       "         11.3027,  9.5577, 11.0530, 11.3657, 11.3382, 12.5589, 12.5589, 12.5938,\n",
       "         11.3317, 12.5589, 10.7469, 12.5589,  9.2237, 12.4946, 11.3628, 11.7220,\n",
       "         12.5589, 12.5962, 12.5589, 11.4144, 11.3892, 10.3107, 12.5911, 11.2671,\n",
       "         11.3739, 11.3759, 12.5589, 11.3309, 12.5589, 12.5589, 12.5589, 10.9381,\n",
       "         12.5253, 12.5589, 11.2008, 12.4533, 11.2187, 12.5951, 12.5589, 12.5589,\n",
       "         11.1641, 12.5699, 12.5589,  7.2096, 10.7535, 12.5589,  7.1906, 12.5953,\n",
       "         12.8120, 12.5589, 12.5589,  9.4965,  7.2120, 12.2162, 10.6714, 11.2770,\n",
       "         12.0661,  9.5404, 12.5589, 10.6003, 12.5589, 11.4830, 12.5589, 12.5589,\n",
       "         12.5307, 12.4585, 12.5589, 12.5589,  7.1750,  7.3073, 12.5589, 12.5589,\n",
       "         12.2809, 12.5589, 12.5589, 12.4526, 12.5589,  7.1924, 11.3312, 11.0953,\n",
       "         11.3805, 11.2630, 11.3430,  7.2700, 11.2094, 12.1146, 11.3304,  7.1940,\n",
       "         12.3151, 12.5184, 12.2567,  7.1909, 12.5589, 10.1669,  7.1844, 12.5589,\n",
       "         10.7601,  7.1733, 11.3825,  9.5188, 11.2816, 12.5589, 12.1398, 10.7730,\n",
       "         12.6114, 11.3790, 11.2591, 11.9582,  9.3306, 12.5589,  7.1909, 11.3706,\n",
       "          7.1787, 10.9199, 11.3145,  9.7192, 12.5963,  9.5596, 12.5589, 12.3030,\n",
       "         12.0273, 12.5589, 12.5589, 12.5589, 12.2405, 10.9551, 12.5589, 12.5589,\n",
       "         12.5589, 12.2375, 11.3513, 11.0327, 11.3300, 12.5589,  7.2009, 12.5589,\n",
       "          9.5070, 11.2250, 12.5589, 11.0039, 12.5589, 12.5589, 12.5589, 12.5589,\n",
       "         11.3318, 11.3125,  9.5605, 12.2942, 12.5843, 12.5589, 12.4676, 12.5589,\n",
       "         12.5589, 12.5589, 12.1927, 12.5589, 11.3007,  7.1898,  9.5211, 12.5589,\n",
       "         12.5589, 12.6168, 13.5019, 11.3666, 12.5858, 12.5589,  9.5467, 12.5589,\n",
       "          7.1888, 12.3040, 12.5589, 12.5589, 11.3306, 11.1665, 12.5589,  7.1897,\n",
       "         12.5884, 12.5589, 12.5589, 11.2235, 12.5589, 10.7401, 11.3316, 11.3720,\n",
       "          7.1741, 11.2938, 12.2888, 12.5589, 12.4700, 11.0995, 12.5589, 11.0364,\n",
       "         12.2748, 11.3333, 11.2837, 11.3847, 11.3714,  9.7400, 12.5589, 11.2773,\n",
       "         11.3306,  7.3067, 11.4362, 12.2866, 11.3622, 11.2244,  7.2261, 12.1822,\n",
       "         11.3756, 10.1107, 12.5562, 12.5589, 11.3746,  9.5335, 10.9496, 12.5589,\n",
       "         12.7795, 12.5550, 12.5589, 10.0220,  9.5091, 11.3259,  9.9299,  7.1926,\n",
       "         12.1931,  7.2084, 12.1797, 12.5589, 11.4261, 11.2639, 11.3621, 12.5589,\n",
       "         11.3311, 10.6587,  9.6065, 11.4256,  9.5584, 12.5589, 12.4901, 11.3316,\n",
       "          7.1911, 10.7515, 12.4946,  7.1776, 12.4102, 12.5589, 10.7537, 12.5589,\n",
       "          7.2805, 10.7359, 12.5589,  9.8473, 12.5589, 12.5325, 10.7457, 11.3730,\n",
       "          7.1910, 12.1859, 11.3303, 12.5589, 11.2456, 12.2237, 11.3873, 11.1713,\n",
       "         10.1546, 11.3702, 12.5589,  7.2162, 11.3291, 11.2194, 12.5841, 12.5589,\n",
       "         12.5569, 12.5589, 11.3300, 12.5589,  9.7063, 11.9071, 11.3288, 12.5589,\n",
       "         11.3121, 10.7519, 12.2153, 12.5589, 12.2868, 12.5589, 12.5535,  8.5879,\n",
       "         11.7110, 11.3536,  7.1818, 12.5913, 12.5965, 12.5589, 11.3830, 12.1487,\n",
       "         11.1797,  7.1880,  9.5212, 12.5589, 12.1948, 12.5589, 12.5589, 11.3732,\n",
       "         12.5589, 11.2862, 12.5589, 10.0924, 11.3321,  7.1934, 12.5456, 12.5589,\n",
       "          7.2035,  7.3075,  9.5602, 12.5589, 12.4703, 11.4437, 12.5589, 12.5589,\n",
       "         12.5589, 11.8006, 12.2537, 12.5589, 12.5589, 12.0747, 10.7508, 11.3289,\n",
       "         11.3351, 11.4013, 12.5589,  9.5136, 12.5589,  7.2065, 10.8581,  9.5970,\n",
       "         11.3751, 12.5589, 10.9025, 10.7520, 12.5239, 11.2367,  9.5578, 10.8234,\n",
       "         11.3347, 11.3300, 12.5589, 12.1163, 11.2614, 12.5589,  7.1940, 12.5589,\n",
       "         11.3434, 12.5197, 11.3233, 12.5589,  7.1904, 11.3358, 12.2980, 12.5589,\n",
       "         11.3305, 11.3299,  7.2824, 11.3800, 12.2897, 12.5589, 12.5589, 11.2787,\n",
       "          7.3046, 12.5589, 11.2627, 11.2485, 12.5589, 12.5589, 11.2458, 12.5589,\n",
       "         12.5589, 11.2565, 11.4739, 11.3666, 12.5589, 12.5589, 12.5589, 12.0525,\n",
       "         12.5589, 11.3300, 12.5589, 11.3171, 12.5589, 11.3885, 12.5589, 11.3827,\n",
       "         11.2251, 12.4281, 11.0997, 12.2481, 12.5589, 12.5589, 11.8599, 12.5589,\n",
       "         11.3316, 11.8405, 12.5589, 12.2422, 11.2609, 12.5589, 12.5589,  7.1891,\n",
       "         12.4440, 12.0661, 12.5942, 12.5589, 11.2453, 12.5589, 12.0800,  7.2065]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
